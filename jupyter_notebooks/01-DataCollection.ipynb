{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and save it as raw data.\n",
        "* Inspect the data and save it under outputs/datasets/raw\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file - the authentication token.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate Dataset:\n",
        "  * outputs/datasets/collection/house_prices_records.csv\n",
        "  * outputs/datasets/collection/inherited_houses.csv\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* For this project, we are fetching data from Kaggle. The first dataset contains the data used to build the machine learning model. The second dataset contains information about the houses inherited by our client, for which we need to predict the prices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\-MY STUDY-\\\\Coding\\\\projects\\\\project-5\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\-MY STUDY-\\\\Coding\\\\projects\\\\project-5'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Fetch data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install Kaggle package to fetch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle==1.5.12\n",
            "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10 in c:\\-my study-\\coding\\projects\\project-5\\.venv\\lib\\site-packages (from kaggle==1.5.12) (1.17.0)\n",
            "Collecting certifi (from kaggle==1.5.12)\n",
            "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: python-dateutil in c:\\-my study-\\coding\\projects\\project-5\\.venv\\lib\\site-packages (from kaggle==1.5.12) (2.9.0.post0)\n",
            "Collecting requests (from kaggle==1.5.12)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tqdm (from kaggle==1.5.12)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting python-slugify (from kaggle==1.5.12)\n",
            "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting urllib3 (from kaggle==1.5.12)\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting text-unidecode>=1.3 (from python-slugify->kaggle==1.5.12)\n",
            "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->kaggle==1.5.12)\n",
            "  Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->kaggle==1.5.12)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: colorama in c:\\-my study-\\coding\\projects\\project-5\\.venv\\lib\\site-packages (from tqdm->kaggle==1.5.12) (0.4.6)\n",
            "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "Installing collected packages: text-unidecode, urllib3, tqdm, python-slugify, idna, charset-normalizer, certifi, requests, kaggle\n",
            "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 kaggle-1.5.12 python-slugify-8.0.4 requests-2.32.3 text-unidecode-1.3 tqdm-4.67.1 urllib3-2.3.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After dragging kaggle.json file run the cell below, so the token is recognized in the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import stat\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "\n",
        "# Set file permissions on Windows\n",
        "kaggle_json_path = os.path.join(os.getcwd(), 'kaggle.json')\n",
        "os.chmod(kaggle_json_path, stat.S_IREAD | stat.S_IWRITE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are using the following [Kaggle URL](https://www.kaggle.com/datasets/codeinstitute/housing-prices-data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading housing-prices-data.zip to inputs/datasets/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0.00/49.6k [00:00<?, ?B/s]\n",
            "100%|██████████| 49.6k/49.6k [00:00<00:00, 465kB/s]\n",
            "100%|██████████| 49.6k/49.6k [00:00<00:00, 461kB/s]\n"
          ]
        }
      ],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/housing-prices-data\"\n",
        "DestinationFolder = \"inputs/datasets/raw\"   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unzip the downloaded file, delete the zip file and delete the kaggle.json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "DestinationFolder = 'inputs/datasets/raw'  # Destination folder for the downloaded dataset\n",
        "\n",
        "# Unzip all .zip files in the destination folder\n",
        "for item in os.listdir(DestinationFolder):\n",
        "    if item.endswith('.zip'):\n",
        "        file_path = os.path.join(DestinationFolder, item)\n",
        "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(DestinationFolder)\n",
        "        os.remove(file_path)  # Remove the zip file after extraction\n",
        "\n",
        "# Remove kaggle.json\n",
        "kaggle_json_path = os.path.join(os.getcwd(), 'kaggle.json')\n",
        "if os.path.exists(kaggle_json_path):\n",
        "    os.remove(kaggle_json_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Load and Inspect Kaggle data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List files in directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs/datasets/raw\\house-metadata.txt\n",
            "inputs/datasets/raw\\house-price-20211124T154130Z-001\\house-price\\house_prices_records.csv\n",
            "inputs/datasets/raw\\house-price-20211124T154130Z-001\\house-price\\inherited_houses.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(\"inputs/datasets/raw\"):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First CSV file:\n",
            "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
            "0       856     854.0           3.0           No         706          GLQ   \n",
            "1      1262       0.0           3.0           Gd         978          ALQ   \n",
            "2       920     866.0           3.0           Mn         486          GLQ   \n",
            "\n",
            "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
            "0        150            0.0         548          RFn  ...         65.0   \n",
            "1        284            NaN         460          RFn  ...         80.0   \n",
            "2        434            0.0         608          RFn  ...         68.0   \n",
            "\n",
            "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
            "0       196.0          61            5            7          856         0.0   \n",
            "1         0.0           0            8            6         1262         NaN   \n",
            "2       162.0          42            5            7          920         NaN   \n",
            "\n",
            "   YearBuilt  YearRemodAdd  SalePrice  \n",
            "0       2003          2003     208500  \n",
            "1       1976          1976     181500  \n",
            "2       2001          2002     223500  \n",
            "\n",
            "[3 rows x 24 columns]\n",
            "\n",
            "Second CSV file:\n",
            "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
            "0       896         0             2           No       468.0          Rec   \n",
            "1      1329         0             3           No       923.0          ALQ   \n",
            "2       928       701             3           No       791.0          GLQ   \n",
            "\n",
            "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotArea  \\\n",
            "0      270.0              0       730.0          Unf  ...    11622   \n",
            "1      406.0              0       312.0          Unf  ...    14267   \n",
            "2      137.0              0       482.0          Fin  ...    13830   \n",
            "\n",
            "   LotFrontage MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  \\\n",
            "0         80.0        0.0            0            6            5        882.0   \n",
            "1         81.0      108.0           36            6            6       1329.0   \n",
            "2         74.0        0.0           34            5            5        928.0   \n",
            "\n",
            "   WoodDeckSF  YearBuilt  YearRemodAdd  \n",
            "0         140       1961          1961  \n",
            "1         393       1958          1958  \n",
            "2         212       1997          1998  \n",
            "\n",
            "[3 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_file_path_1 = \"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\"\n",
        "csv_file_path_2 = \"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/inherited_houses.csv\"\n",
        "\n",
        "# Load the CSV files\n",
        "df1 = pd.read_csv(csv_file_path_1)\n",
        "df2 = pd.read_csv(csv_file_path_2)\n",
        "\n",
        "# Inspect the first few rows of each DataFrame\n",
        "print(\"First CSV file:\")\n",
        "print(df1.head(3))\n",
        "\n",
        "print(\"\\nSecond CSV file:\")\n",
        "print(df2.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DataFrame Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 24 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   1stFlrSF       1460 non-null   int64  \n",
            " 1   2ndFlrSF       1374 non-null   float64\n",
            " 2   BedroomAbvGr   1361 non-null   float64\n",
            " 3   BsmtExposure   1422 non-null   object \n",
            " 4   BsmtFinSF1     1460 non-null   int64  \n",
            " 5   BsmtFinType1   1315 non-null   object \n",
            " 6   BsmtUnfSF      1460 non-null   int64  \n",
            " 7   EnclosedPorch  136 non-null    float64\n",
            " 8   GarageArea     1460 non-null   int64  \n",
            " 9   GarageFinish   1225 non-null   object \n",
            " 10  GarageYrBlt    1379 non-null   float64\n",
            " 11  GrLivArea      1460 non-null   int64  \n",
            " 12  KitchenQual    1460 non-null   object \n",
            " 13  LotArea        1460 non-null   int64  \n",
            " 14  LotFrontage    1201 non-null   float64\n",
            " 15  MasVnrArea     1452 non-null   float64\n",
            " 16  OpenPorchSF    1460 non-null   int64  \n",
            " 17  OverallCond    1460 non-null   int64  \n",
            " 18  OverallQual    1460 non-null   int64  \n",
            " 19  TotalBsmtSF    1460 non-null   int64  \n",
            " 20  WoodDeckSF     155 non-null    float64\n",
            " 21  YearBuilt      1460 non-null   int64  \n",
            " 22  YearRemodAdd   1460 non-null   int64  \n",
            " 23  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(7), int64(13), object(4)\n",
            "memory usage: 273.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 23 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   1stFlrSF       4 non-null      int64  \n",
            " 1   2ndFlrSF       4 non-null      int64  \n",
            " 2   BedroomAbvGr   4 non-null      int64  \n",
            " 3   BsmtExposure   4 non-null      object \n",
            " 4   BsmtFinSF1     4 non-null      float64\n",
            " 5   BsmtFinType1   4 non-null      object \n",
            " 6   BsmtUnfSF      4 non-null      float64\n",
            " 7   EnclosedPorch  4 non-null      int64  \n",
            " 8   GarageArea     4 non-null      float64\n",
            " 9   GarageFinish   4 non-null      object \n",
            " 10  GarageYrBlt    4 non-null      float64\n",
            " 11  GrLivArea      4 non-null      int64  \n",
            " 12  KitchenQual    4 non-null      object \n",
            " 13  LotArea        4 non-null      int64  \n",
            " 14  LotFrontage    4 non-null      float64\n",
            " 15  MasVnrArea     4 non-null      float64\n",
            " 16  OpenPorchSF    4 non-null      int64  \n",
            " 17  OverallCond    4 non-null      int64  \n",
            " 18  OverallQual    4 non-null      int64  \n",
            " 19  TotalBsmtSF    4 non-null      float64\n",
            " 20  WoodDeckSF     4 non-null      int64  \n",
            " 21  YearBuilt      4 non-null      int64  \n",
            " 22  YearRemodAdd   4 non-null      int64  \n",
            "dtypes: float64(7), int64(12), object(4)\n",
            "memory usage: 868.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "df2.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SUMMARY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The first dataset contains information about 1460 houses from Ames, Iowa. It includes 24 columns with various attributes related to the houses. The columns have different data types: 13 columns are of type int64, 7 columns are of type float64, and 4 columns are of type object.\n",
        "\n",
        "Some columns have missing values, as indicated by the non-null counts.\n",
        "\n",
        "* The second dataset contains information about the four houses inherited by our client. It includes 23 columns with various attributes related to these houses. The columns have different data types: 12 columns are of type `int64`, 7 columns are of type `float64`, and 4 columns are of type `object`.\n",
        "\n",
        "All columns have non-null values, indicating that there are no missing values in this dataset. The attributes included in this dataset are similar to those in the first dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "In this notebook, we have collected data from Kaggle and inspected the columns in the dataset.\n",
        "\n",
        "From the initial inspection, it is evident that the data needs to be cleaned before any analysis can be performed. We will now push the datasets to the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the directory path\n",
        "directory_path = 'outputs/datasets/collection'\n",
        "\n",
        "try:\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(name=directory_path, exist_ok=True)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Save df1 and df2 as CSV files in the created directory\n",
        "df1.to_csv(os.path.join(directory_path, 'house_prices_records.csv'), index=False)\n",
        "df2.to_csv(os.path.join(directory_path, 'inherited_houses.csv'), index=False)\n",
        "\n",
        "# Add the datasets to the repository\n",
        "os.system('git add outputs/datasets/collection/house_prices_records.csv')\n",
        "os.system('git add outputs/datasets/collection/inherited_houses.csv')\n",
        "\n",
        "# Commit the changes with a message\n",
        "os.system('git commit -m \"Add Kaggle datasets for house prices and inherited houses\"')\n",
        "\n",
        "# Push the changes to the remote repository\n",
        "os.system('git push origin main')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
